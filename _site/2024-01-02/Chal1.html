<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>Taehan Kim</title>

  <!-- CSS -->
  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Libre+Baskerville:400,400i,700">
  
  <!-- Font Awesome -->
  <link rel="stylesheet" type="text/css" href="/assets/css/fontawesome-all.min.css">

  <!-- Favicon -->
  <link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon.ico">

  <!-- Google Analytics -->
  

</head>


  <body>
    <nav class="nav">
      <div class="nav-container">
        <a href="/">
          <h2 class="nav-title">Taehan Kim</h2>
        </a>
        <ul>
          <li><a href="/">About</a></li>
          <li><a href="/work/">Work</a></li>
        </ul>
    </div>
  </nav>

    <main>
      <div class="post">
  <h2 class="post-title">Speech Signal Improvement Challenge - ICASSP2024</h2>
  <div class="post-line"></div>

  <!-- 
## Description


## Tech
'*' : tech I focus on


## My job -->

<h1 id="task-describtion">Task Describtion</h1>
<p>This project was part of the Speech Signal Improvement Challenge 2024, where we participated in the Real-time track. The main objective was to improve speech signal quality in real-time, targeting environments with diverse noise sources and challenging acoustics. 
<br /></p>

<h2 id="background">Background</h2>
<p>The challenge evaluated speech enhancement systems in both real-time and non-real-time tracks. The real-time track, in particular, focused on improving speech quality for communication systems in noisy environments, considering metrics like Word Accuracy (WAcc) and ITU-T P.835 subjective evaluations. We developed an advanced deep learning model that successfully enhanced speech signals in real-time, addressing issues like low signal-to-noise ratio (SNR), reverberation, and interference from multiple speakers.
<br /></p>

<h2 id="proposed-solution">Proposed Solution</h2>
<div style="display: flex; justify-content: center;">
  <img src="../assets/img/work/Chal1_fr.png" alt="Image 1" style="width: 100%; display: inline-block; margin-right: 2%;" />
</div>
<ul>
  <li>Frequency Rolling (FR) : This process effectively rolled the frequency axis into the channel axis, allowing grouped convolutions to handle the frequencies separately with a reduced computational footprint.</li>
  <li>Frequency-wise Self-Attention with Time-wise LSTM for Causality
<br /></li>
</ul>

<h1 id="outcome">Outcome</h1>
<div style="display: flex; justify-content: center;">
  <img src="../assets/img/work/Chal1.png" alt="Image 1" style="width: 100%; display: inline-block; margin-right: 2%;" />
</div>
<p>We ranked 5th out of 13 teams in the Real-time Track.
<br /></p>

<h1 id="my-contributions">My Contributions</h1>
<ul>
  <li>I applied Frequency Rolling (FR) because I found it effective in reducing computational complexity without significantly degrading performance. This approach has been successfully used in previous research on music separation, where rolling the frequency axis into the channel axis improved efficiency while preserving the modelâ€™s capacity to handle frequency domain information.
<br /></li>
</ul>


</div>

<div class="pagination">
  
    <a href="/2024-02-01/P7" class="left next">Prev</a>
  
  
    <a href="/2024-01-01/Conf1" class="right next">Next</a>
  

  <a href="#" class="top">Top</a>
</div>

    </main>

    <footer>
      <span>
        &copy; <time datetime="2024-09-06 02:09:53 -0400">2024</time> Taehan Kim. <a href="https://github.com/kssim/about-portfolio/">A.P</a> theme by kssim.
      </span>
    </footer>
  </body>
</html>
